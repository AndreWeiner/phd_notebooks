{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SGS model assemblies\n",
    "\n",
    "This notebook creates and exports wrapper models to be used in OpenFOAM simulations. Each wrapper model hides the single MLP models for diffusive and convective fluxes for one species. The wrapper model also contains constants to scale and rescale model inputs and outputs.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "Notebooks (links work only if the Docker container is running)\n",
    "\n",
    "- [create_sgs_models.ipynb](http://127.0.0.1:8888/notebooks/create_sgs_models.ipynb)\n",
    "- [reduce_training_data.ipynb](http://127.0.0.1:8888/notebooks/reduce_training_data.ipynb)\n",
    "\n",
    "## Model assemblies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_module as hm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data_path = \"../data/sgs_data/\"\n",
    "output_path_model = \"../output/models/\"\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions = [\"phys\", \"decay\", \"single\", \"cons\"]\n",
    "data_files = {}\n",
    "for r in reactions:\n",
    "    path = data_path + \"{:s}_red.csv\".format(r)\n",
    "    data_files[r] = pd.read_csv(path, header=0)\n",
    "    \n",
    "model_dict = {\n",
    "    \"n_inputs\" : 2,\n",
    "    \"n_outputs\" : 1,\n",
    "    \"n_layers\" : 6,\n",
    "    \"n_neurons\" : 40,\n",
    "    \"activation\" : torch.nn.functional.relu,\n",
    "    \"batch_norm\" : False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A_Model(torch.nn.Module):\n",
    "    def __init__(self, modelGrad_s, modelGrad_f, model_f, X_max, X_min, y_max, y_min):\n",
    "        super().__init__()\n",
    "        self.modelGrad_s = modelGrad_s\n",
    "        self.modelGrad_f = modelGrad_f\n",
    "        self.model_f = model_f\n",
    "        self.X_max = torch.tensor(X_max, dtype=torch.float64)\n",
    "        self.X_min = torch.tensor(X_min, dtype=torch.float64)\n",
    "        self.grad_s_max = torch.tensor(y_max[0], dtype=torch.float64)\n",
    "        self.grad_s_min = torch.tensor(y_min[0], dtype=torch.float64)\n",
    "        self.grad_f_max = torch.tensor(y_max[1], dtype=torch.float64)\n",
    "        self.grad_f_min = torch.tensor(y_min[1], dtype=torch.float64)\n",
    "        self.f_max = torch.tensor(y_max[2], dtype=torch.float64)\n",
    "        self.f_min = torch.tensor(y_min[2], dtype=torch.float64)\n",
    "        \n",
    "    def forward(self, Xorg):\n",
    "        X = Xorg.clone()\n",
    "        X.requires_grad_(False)\n",
    "        X = (X - self.X_min) / (self.X_max - self.X_min)\n",
    "        grad_s = self.modelGrad_s(X)\n",
    "        grad_f = self.modelGrad_f(X)\n",
    "        f = self.model_f(X)\n",
    "        grad_s = grad_s * (self.grad_s_max - self.grad_s_min) + self.grad_s_min\n",
    "        grad_f = grad_f * (self.grad_f_max - self.grad_f_min) + self.grad_f_min\n",
    "        f = f * (self.f_max - self.f_min) + self.f_min\n",
    "        return torch.cat((grad_s, grad_f, f), 1)\n",
    "\n",
    "    \n",
    "class BPS_Model(torch.nn.Module):\n",
    "    def __init__(self, modelGrad_f, model_f, X_max, X_min, y_max, y_min):\n",
    "        super().__init__()\n",
    "        self.modelGrad_f = modelGrad_f\n",
    "        self.model_f = model_f\n",
    "        self.X_max = torch.tensor(X_max, dtype=torch.float64)\n",
    "        self.X_min = torch.tensor(X_min, dtype=torch.float64)\n",
    "        self.grad_f_max = torch.tensor(y_max[0], dtype=torch.float64)\n",
    "        self.grad_f_min = torch.tensor(y_min[0], dtype=torch.float64)\n",
    "        self.f_max = torch.tensor(y_max[1], dtype=torch.float64)\n",
    "        self.f_min = torch.tensor(y_min[1], dtype=torch.float64)\n",
    "        \n",
    "    def forward(self, Xorg):\n",
    "        X = Xorg.clone()\n",
    "        X.requires_grad_(False)\n",
    "        X = (X - self.X_min) / (self.X_max - self.X_min)\n",
    "        grad_f = self.modelGrad_f(X)\n",
    "        f = self.model_f(X)\n",
    "        grad_f = grad_f * (self.grad_f_max - self.grad_f_min) + self.grad_f_min\n",
    "        f = f * (self.f_max - self.f_min) + self.f_min\n",
    "        return torch.cat((grad_f, f), 1)\n",
    "    \n",
    "    \n",
    "class R_Model(torch.nn.Module):\n",
    "    def __init__(self, model_r, X_max, X_min, y_max, y_min):\n",
    "        super().__init__()\n",
    "        self.model_r = model_r\n",
    "        self.X_max = torch.tensor(X_max, dtype=torch.float64)\n",
    "        self.X_min = torch.tensor(X_min, dtype=torch.float64)\n",
    "        self.r_max = torch.tensor(y_max[0], dtype=torch.float64)\n",
    "        self.r_min = torch.tensor(y_min[0], dtype=torch.float64)\n",
    "        \n",
    "    def forward(self, Xorg):\n",
    "        X = Xorg.clone()\n",
    "        X.requires_grad_(False)\n",
    "        X = (X - self.X_min) / (self.X_max - self.X_min)\n",
    "        r = self.model_r(X)\n",
    "        r = r * (self.r_max - self.r_min) + self.r_min\n",
    "        return r.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physisorption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min:  [ 0.00014647  0.0190299 ]\n",
      "feature max:  [ 0.02410139  0.99999401]\n",
      "label min:  [ -1.35246401e+03  -1.29050920e+03   4.91842585e-35]\n",
      "label max:  [ -8.16929972e-02  -5.09789595e-30   9.99988034e-01]\n"
     ]
    }
   ],
   "source": [
    "data = data_files[\"phys\"]\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X01 = scaler_X.fit_transform(data[[\"dist\", \"A_av\"]].values)\n",
    "y01 = scaler_y.fit_transform(data[[\"gradA_s\", \"gradA_f\", \"A_f\"]].values)\n",
    "print(\"feature min: \", scaler_X.data_min_)\n",
    "print(\"feature max: \", scaler_X.data_max_)\n",
    "print(\"label min: \", scaler_y.data_min_)\n",
    "print(\"label max: \", scaler_y.data_max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"n_inputs\"] = 2\n",
    "\n",
    "modelGrad_s = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"phys_gradA_s.pt\"\n",
    "modelGrad_s.load_state_dict(torch.load(model_path))\n",
    "modelGrad_s.eval()\n",
    "\n",
    "modelGrad_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"phys_gradA_f.pt\"\n",
    "modelGrad_f.load_state_dict(torch.load(model_path))\n",
    "modelGrad_f.eval()\n",
    "\n",
    "model_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"phys_A_f.pt\"\n",
    "model_f.load_state_dict(torch.load(model_path))\n",
    "model_f.eval()\n",
    "\n",
    "full_A_model = A_Model(modelGrad_s, modelGrad_f, model_f,\n",
    "                       scaler_X.data_max_, scaler_X.data_min_,\n",
    "                       scaler_y.data_max_, scaler_y.data_min_)\n",
    "\n",
    "X = data[[\"dist\", \"A_av\"]].values\n",
    "model_trace = torch.jit.trace(full_A_model, torch.from_numpy(X[0]).unsqueeze(-1).T)\n",
    "model_trace.save(output_path_model + \"A_model_phys.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.21585444e+01   6.45445141e+01   1.17640193e-02]\n"
     ]
    }
   ],
   "source": [
    "# sanity test\n",
    "A_model_phys = torch.jit.load(output_path_model + \"A_model_phys.pt\")\n",
    "X = data[[\"dist\", \"A_av\"]].values\n",
    "y = data[[\"gradA_s\", \"gradA_f\", \"A_f\"]].values\n",
    "ym = A_model_phys(torch.from_numpy(X)).detach().numpy()\n",
    "diff = ym - y\n",
    "print(np.amax(diff, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decay reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature A min:  [ 0.00014647  0.01901263]\n",
      "feature A max:  [ 0.02410139  0.99720645]\n",
      "feature P min:  [  1.46467255e-04   1.90126266e-02   3.33921849e-05]\n",
      "feature P max:  [ 0.02410139  0.99720645  0.75023927]\n",
      "label A min:  [ -1.35586926e+03  -1.29241793e+03   4.90573895e-35]\n",
      "label A max:  [ -3.81287791e+01  -5.08476988e-30   9.94569296e-01]\n",
      "label P min:  [ -1.38447926e+01   1.28078564e-37]\n",
      "label P max:  [ -1.32709894e-32   7.50232730e-01]\n"
     ]
    }
   ],
   "source": [
    "data = data_files[\"decay\"]\n",
    "scaler_X_A = MinMaxScaler()\n",
    "scaler_X_P = MinMaxScaler()\n",
    "scaler_y_A = MinMaxScaler()\n",
    "scaler_y_P = MinMaxScaler()\n",
    "X01_A = scaler_X_A.fit_transform(data[[\"dist\", \"A_av\"]].values)\n",
    "y01_A = scaler_y_A.fit_transform(data[[\"gradA_s\", \"gradA_f\", \"A_f\"]])\n",
    "X01_P = scaler_X_P.fit_transform(data[[\"dist\", \"A_av\", \"P_av\"]].values)\n",
    "y01_P = scaler_y_P.fit_transform(data[[\"gradP_f\", \"P_f\"]])\n",
    "print(\"feature A min: \", scaler_X_A.data_min_)\n",
    "print(\"feature A max: \", scaler_X_A.data_max_)\n",
    "print(\"feature P min: \", scaler_X_P.data_min_)\n",
    "print(\"feature P max: \", scaler_X_P.data_max_)\n",
    "print(\"label A min: \", scaler_y_A.data_min_)\n",
    "print(\"label A max: \", scaler_y_A.data_max_)\n",
    "print(\"label P min: \", scaler_y_P.data_min_)\n",
    "print(\"label P max: \", scaler_y_P.data_max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"n_inputs\"] = 2\n",
    "\n",
    "modelGrad_s = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"decay_gradA_s.pt\"\n",
    "modelGrad_s.load_state_dict(torch.load(model_path))\n",
    "modelGrad_s.eval()\n",
    "\n",
    "modelGrad_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"decay_gradA_f.pt\"\n",
    "modelGrad_f.load_state_dict(torch.load(model_path))\n",
    "modelGrad_f.eval()\n",
    "\n",
    "model_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"decay_A_f.pt\"\n",
    "model_f.load_state_dict(torch.load(model_path))\n",
    "model_f.eval()\n",
    "\n",
    "full_A_model = A_Model(modelGrad_s, modelGrad_f, model_f,\n",
    "                       scaler_X_A.data_max_, scaler_X_A.data_min_,\n",
    "                       scaler_y_A.data_max_, scaler_y_A.data_min_)\n",
    "\n",
    "X = data[[\"dist\", \"A_av\"]].values\n",
    "model_trace = torch.jit.trace(full_A_model, torch.from_numpy(X[0]).unsqueeze(-1).T)\n",
    "model_trace.save(output_path_model + \"A_model_decay.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.19395579e+01   1.20408302e+02   2.06899039e-02]\n"
     ]
    }
   ],
   "source": [
    "# sanity test\n",
    "A_model_decay = torch.jit.load(output_path_model + \"A_model_decay.pt\")\n",
    "X = data[[\"dist\", \"A_av\"]].values\n",
    "y = data[[\"gradA_s\", \"gradA_f\", \"A_f\"]].values\n",
    "ym = A_model_decay(torch.from_numpy(X)).detach().numpy()\n",
    "diff = ym - y\n",
    "print(np.amax(diff, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"n_inputs\"] = 3\n",
    "\n",
    "modelGrad_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"decay_gradP_f.pt\"\n",
    "modelGrad_f.load_state_dict(torch.load(model_path))\n",
    "modelGrad_f.eval()\n",
    "\n",
    "model_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"decay_P_f.pt\"\n",
    "model_f.load_state_dict(torch.load(model_path))\n",
    "model_f.eval()\n",
    "\n",
    "full_P_model = BPS_Model(modelGrad_f, model_f,\n",
    "                         scaler_X_P.data_max_, scaler_X_P.data_min_,\n",
    "                         scaler_y_P.data_max_, scaler_y_P.data_min_)\n",
    "\n",
    "X = data[[\"dist\", \"A_av\", \"P_av\"]].values\n",
    "model_trace = torch.jit.trace(full_P_model, torch.from_numpy(X[0]).unsqueeze(-1).T)\n",
    "model_trace.save(output_path_model + \"P_model_decay.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6124376   0.00449567]\n"
     ]
    }
   ],
   "source": [
    "# sanity test\n",
    "P_model_decay = torch.jit.load(output_path_model + \"P_model_decay.pt\")\n",
    "X = data[[\"dist\", \"A_av\", \"P_av\"]].values\n",
    "y = data[[\"gradP_f\", \"P_f\"]].values\n",
    "ym = P_model_decay(torch.from_numpy(X)).detach().numpy()\n",
    "diff = ym - y\n",
    "print(np.amax(diff, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature AB min:  [  1.46467255e-04   1.90126350e-02   4.70975454e-01]\n",
      "feature AB max:  [ 0.02410139  0.99859163  0.99996662]\n",
      "feature P min:  [  1.46467255e-04   1.90126350e-02   4.70975454e-01   3.33757974e-05]\n",
      "feature P max:  [ 0.02410139  0.99859163  0.99996662  0.52902455]\n",
      "label A min:  [ -1.35586645e+03  -1.29241664e+03   4.90573899e-35]\n",
      "label A max:  [ -1.92225543e+01  -5.08476992e-30   9.97257107e-01]\n",
      "label B min:  [-0.03779494  0.47097706]\n",
      "label B max:  [ 13.20692147   1.        ]\n",
      "label P min:  [ -1.32069215e+01   1.28078072e-37]\n",
      "label P max:  [ 0.03779494  0.52902294]\n"
     ]
    }
   ],
   "source": [
    "data = data_files[\"single\"]\n",
    "scaler_X_AB = MinMaxScaler()\n",
    "scaler_X_P = MinMaxScaler()\n",
    "scaler_y_A = MinMaxScaler()\n",
    "scaler_y_B = MinMaxScaler()\n",
    "scaler_y_P = MinMaxScaler()\n",
    "X01_AB = scaler_X_AB.fit_transform(data[[\"dist\", \"A_av\", \"B_av\"]].values)\n",
    "y01_A = scaler_y_A.fit_transform(data[[\"gradA_s\", \"gradA_f\", \"A_f\"]])\n",
    "y01_B = scaler_y_B.fit_transform(data[[\"gradB_f\", \"B_f\"]])\n",
    "X01_P = scaler_X_P.fit_transform(data[[\"dist\", \"A_av\", \"B_av\", \"P_av\"]].values)\n",
    "y01_P = scaler_y_P.fit_transform(data[[\"gradP_f\", \"P_f\"]])\n",
    "print(\"feature AB min: \", scaler_X_AB.data_min_)\n",
    "print(\"feature AB max: \", scaler_X_AB.data_max_)\n",
    "print(\"feature P min: \", scaler_X_P.data_min_)\n",
    "print(\"feature P max: \", scaler_X_P.data_max_)\n",
    "print(\"label A min: \", scaler_y_A.data_min_)\n",
    "print(\"label A max: \", scaler_y_A.data_max_)\n",
    "print(\"label B min: \", scaler_y_B.data_min_)\n",
    "print(\"label B max: \", scaler_y_B.data_max_)\n",
    "print(\"label P min: \", scaler_y_P.data_min_)\n",
    "print(\"label P max: \", scaler_y_P.data_max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"n_inputs\"] = 3\n",
    "\n",
    "modelGrad_s = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"single_gradA_s.pt\"\n",
    "modelGrad_s.load_state_dict(torch.load(model_path))\n",
    "modelGrad_s.eval()\n",
    "\n",
    "modelGrad_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"single_gradA_f.pt\"\n",
    "modelGrad_f.load_state_dict(torch.load(model_path))\n",
    "modelGrad_f.eval()\n",
    "\n",
    "model_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"single_A_f.pt\"\n",
    "model_f.load_state_dict(torch.load(model_path))\n",
    "model_f.eval()\n",
    "\n",
    "full_A_model = A_Model(modelGrad_s, modelGrad_f, model_f,\n",
    "                       scaler_X_AB.data_max_, scaler_X_AB.data_min_,\n",
    "                       scaler_y_A.data_max_, scaler_y_A.data_min_)\n",
    "\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\"]].values\n",
    "model_trace = torch.jit.trace(full_A_model, torch.from_numpy(X[0]).unsqueeze(-1).T)\n",
    "model_trace.save(output_path_model + \"A_model_single.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.11384190e+02   1.27767044e+02   9.42756475e-03]\n"
     ]
    }
   ],
   "source": [
    "# sanity test\n",
    "A_model_single = torch.jit.load(output_path_model + \"A_model_single.pt\")\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\"]].values\n",
    "y = data[[\"gradA_s\", \"gradA_f\", \"A_f\"]].values\n",
    "ym = A_model_single(torch.from_numpy(X)).detach().numpy()\n",
    "diff = ym - y\n",
    "print(np.amax(diff, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"n_inputs\"] = 3\n",
    "\n",
    "modelGrad_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"single_gradB_f.pt\"\n",
    "modelGrad_f.load_state_dict(torch.load(model_path))\n",
    "modelGrad_f.eval()\n",
    "\n",
    "model_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"single_B_f.pt\"\n",
    "model_f.load_state_dict(torch.load(model_path))\n",
    "model_f.eval()\n",
    "\n",
    "full_B_model = BPS_Model(modelGrad_f, model_f,\n",
    "                         scaler_X_AB.data_max_, scaler_X_AB.data_min_,\n",
    "                         scaler_y_B.data_max_, scaler_y_B.data_min_)\n",
    "\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\"]].values\n",
    "model_trace = torch.jit.trace(full_B_model, torch.from_numpy(X[0]).unsqueeze(-1).T)\n",
    "model_trace.save(output_path_model + \"B_model_single.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95675585  0.0074362 ]\n"
     ]
    }
   ],
   "source": [
    "# sanity test\n",
    "B_model_single = torch.jit.load(output_path_model + \"B_model_single.pt\")\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\"]].values\n",
    "y = data[[\"gradB_f\", \"B_f\"]].values\n",
    "ym = B_model_single(torch.from_numpy(X)).detach().numpy()\n",
    "diff = ym - y\n",
    "print(np.amax(diff, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"n_inputs\"] = 4\n",
    "\n",
    "modelGrad_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"single_gradP_f.pt\"\n",
    "modelGrad_f.load_state_dict(torch.load(model_path))\n",
    "modelGrad_f.eval()\n",
    "\n",
    "model_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"single_P_f.pt\"\n",
    "model_f.load_state_dict(torch.load(model_path))\n",
    "model_f.eval()\n",
    "\n",
    "full_P_model = BPS_Model(modelGrad_f, model_f,\n",
    "                         scaler_X_P.data_max_, scaler_X_P.data_min_,\n",
    "                         scaler_y_P.data_max_, scaler_y_P.data_min_)\n",
    "\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\", \"P_av\"]].values\n",
    "model_trace = torch.jit.trace(full_P_model, torch.from_numpy(X[0]).unsqueeze(-1).T)\n",
    "model_trace.save(output_path_model + \"P_model_single.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.61555782  0.00356164]\n"
     ]
    }
   ],
   "source": [
    "# sanity test\n",
    "P_model_single = torch.jit.load(output_path_model + \"P_model_single.pt\")\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\", \"P_av\"]].values\n",
    "y = data[[\"gradP_f\", \"P_f\"]].values\n",
    "ym = P_model_single(torch.from_numpy(X)).detach().numpy()\n",
    "diff = ym - y\n",
    "print(np.amax(diff, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consecutive reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature ABP min:  [  1.46467255e-04   1.90126183e-02   4.76073262e-01   3.33430253e-05]\n",
      "feature ABP max:  [ 0.02410139  0.99723356  0.99996662  0.24925557]\n",
      "feature ABPS min:  [  1.46467255e-04   1.90126183e-02   4.76073262e-01   3.33430253e-05\n",
      "   3.27622541e-08]\n",
      "feature ABPS max:  [ 0.02410139  0.99723356  0.99996662  0.24925557  0.27699298]\n",
      "label A min:  [ -1.35587207e+03  -1.29241923e+03   4.90573891e-35]\n",
      "label A max:  [ -3.77586549e+01  -5.08476984e-30   9.94619004e-01]\n",
      "label B min:  [ -5.45260155e-09   4.76076392e-01]\n",
      "label B max:  [ 13.19452088   1.        ]\n",
      "label P min:  [ -1.20215621e+01   1.28077084e-37]\n",
      "label P max:  [ 0.00755388  0.24925554]\n",
      "label S min:  [ -1.72322236e+00   9.88635155e-43]\n",
      "label S max:  [ -1.11352039e-37   2.76989729e-01]\n"
     ]
    }
   ],
   "source": [
    "data = data_files[\"cons\"]\n",
    "scaler_X_ABP = MinMaxScaler()\n",
    "scaler_X_ABPS = MinMaxScaler()\n",
    "scaler_y_A = MinMaxScaler()\n",
    "scaler_y_B = MinMaxScaler()\n",
    "scaler_y_P = MinMaxScaler()\n",
    "scaler_y_S = MinMaxScaler()\n",
    "X01_ABP = scaler_X_ABP.fit_transform(data[[\"dist\", \"A_av\", \"B_av\", \"P_av\"]].values)\n",
    "y01_A = scaler_y_A.fit_transform(data[[\"gradA_s\", \"gradA_f\", \"A_f\"]])\n",
    "y01_B = scaler_y_B.fit_transform(data[[\"gradB_f\", \"B_f\"]])\n",
    "y01_P = scaler_y_P.fit_transform(data[[\"gradP_f\", \"P_f\"]])\n",
    "X01_ABPS = scaler_X_ABPS.fit_transform(data[[\"dist\", \"A_av\", \"B_av\", \"P_av\", \"S_av\"]].values)\n",
    "y01_S = scaler_y_S.fit_transform(data[[\"gradS_f\", \"S_f\"]])\n",
    "print(\"feature ABP min: \", scaler_X_ABP.data_min_)\n",
    "print(\"feature ABP max: \", scaler_X_ABP.data_max_)\n",
    "print(\"feature ABPS min: \", scaler_X_ABPS.data_min_)\n",
    "print(\"feature ABPS max: \", scaler_X_ABPS.data_max_)\n",
    "print(\"label A min: \", scaler_y_A.data_min_)\n",
    "print(\"label A max: \", scaler_y_A.data_max_)\n",
    "print(\"label B min: \", scaler_y_B.data_min_)\n",
    "print(\"label B max: \", scaler_y_B.data_max_)\n",
    "print(\"label P min: \", scaler_y_P.data_min_)\n",
    "print(\"label P max: \", scaler_y_P.data_max_)\n",
    "print(\"label S min: \", scaler_y_S.data_min_)\n",
    "print(\"label S max: \", scaler_y_S.data_max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"n_inputs\"] = 4\n",
    "\n",
    "modelGrad_s = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"cons_gradA_s.pt\"\n",
    "modelGrad_s.load_state_dict(torch.load(model_path))\n",
    "modelGrad_s.eval()\n",
    "\n",
    "modelGrad_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"cons_gradA_f.pt\"\n",
    "modelGrad_f.load_state_dict(torch.load(model_path))\n",
    "modelGrad_f.eval()\n",
    "\n",
    "model_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"cons_A_f.pt\"\n",
    "model_f.load_state_dict(torch.load(model_path))\n",
    "model_f.eval()\n",
    "\n",
    "full_A_model = A_Model(modelGrad_s, modelGrad_f, model_f,\n",
    "                       scaler_X_ABP.data_max_, scaler_X_ABP.data_min_,\n",
    "                       scaler_y_A.data_max_, scaler_y_A.data_min_)\n",
    "\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\", \"P_av\"]].values\n",
    "model_trace = torch.jit.trace(full_A_model, torch.from_numpy(X[0]).unsqueeze(-1).T)\n",
    "model_trace.save(output_path_model + \"A_model_cons.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.06967755e+02   1.02455355e+02   8.99112268e-03]\n"
     ]
    }
   ],
   "source": [
    "# sanity test\n",
    "A_model_cons = torch.jit.load(output_path_model + \"A_model_cons.pt\")\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\", \"P_av\"]].values\n",
    "y = data[[\"gradA_s\", \"gradA_f\", \"A_f\"]].values\n",
    "ym = A_model_cons(torch.from_numpy(X)).detach().numpy()\n",
    "diff = ym - y\n",
    "print(np.amax(diff, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"n_inputs\"] = 4\n",
    "\n",
    "modelGrad_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"cons_gradB_f.pt\"\n",
    "modelGrad_f.load_state_dict(torch.load(model_path))\n",
    "modelGrad_f.eval()\n",
    "\n",
    "model_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"cons_B_f.pt\"\n",
    "model_f.load_state_dict(torch.load(model_path))\n",
    "model_f.eval()\n",
    "\n",
    "full_B_model = BPS_Model(modelGrad_f, model_f,\n",
    "                         scaler_X_ABP.data_max_, scaler_X_ABP.data_min_,\n",
    "                         scaler_y_B.data_max_, scaler_y_B.data_min_)\n",
    "\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\", \"P_av\"]].values\n",
    "model_trace = torch.jit.trace(full_B_model, torch.from_numpy(X[0]).unsqueeze(-1).T)\n",
    "model_trace.save(output_path_model + \"B_model_cons.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.58645418  0.0124481 ]\n"
     ]
    }
   ],
   "source": [
    "# sanity test\n",
    "B_model_cons = torch.jit.load(output_path_model + \"B_model_cons.pt\")\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\", \"P_av\"]].values\n",
    "y = data[[\"gradB_f\", \"B_f\"]].values\n",
    "ym = B_model_cons(torch.from_numpy(X)).detach().numpy()\n",
    "diff = ym - y\n",
    "print(np.amax(diff, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"n_inputs\"] = 4\n",
    "\n",
    "modelGrad_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"cons_gradP_f.pt\"\n",
    "modelGrad_f.load_state_dict(torch.load(model_path))\n",
    "modelGrad_f.eval()\n",
    "\n",
    "model_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"cons_P_f.pt\"\n",
    "model_f.load_state_dict(torch.load(model_path))\n",
    "model_f.eval()\n",
    "\n",
    "full_P_model = BPS_Model(modelGrad_f, model_f,\n",
    "                         scaler_X_ABP.data_max_, scaler_X_ABP.data_min_,\n",
    "                         scaler_y_P.data_max_, scaler_y_P.data_min_)\n",
    "\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\", \"P_av\"]].values\n",
    "model_trace = torch.jit.trace(full_P_model, torch.from_numpy(X[0]).unsqueeze(-1).T)\n",
    "model_trace.save(output_path_model + \"P_model_cons.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.19858018  0.00173992]\n"
     ]
    }
   ],
   "source": [
    "# sanity test\n",
    "P_model_cons = torch.jit.load(output_path_model + \"P_model_cons.pt\")\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\", \"P_av\"]].values\n",
    "y = data[[\"gradP_f\", \"P_f\"]].values\n",
    "ym = P_model_cons(torch.from_numpy(X)).detach().numpy()\n",
    "diff = ym - y\n",
    "print(np.amax(diff, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"n_inputs\"] = 5\n",
    "\n",
    "modelGrad_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"cons_gradS_f.pt\"\n",
    "modelGrad_f.load_state_dict(torch.load(model_path))\n",
    "modelGrad_f.eval()\n",
    "\n",
    "model_f = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"cons_S_f.pt\"\n",
    "model_f.load_state_dict(torch.load(model_path))\n",
    "model_f.eval()\n",
    "\n",
    "full_S_model = BPS_Model(modelGrad_f, model_f,\n",
    "                         scaler_X_ABPS.data_max_, scaler_X_ABPS.data_min_,\n",
    "                         scaler_y_S.data_max_, scaler_y_S.data_min_)\n",
    "\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\", \"P_av\", \"S_av\"]].values\n",
    "model_trace = torch.jit.trace(full_S_model, torch.from_numpy(X[0]).unsqueeze(-1).T)\n",
    "model_trace.save(output_path_model + \"S_model_cons.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1011508   0.00194043]\n"
     ]
    }
   ],
   "source": [
    "# sanity test\n",
    "S_model_cons = torch.jit.load(output_path_model + \"S_model_cons.pt\")\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\", \"P_av\", \"S_av\"]].values\n",
    "y = data[[\"gradS_f\", \"S_f\"]].values\n",
    "ym = S_model_cons(torch.from_numpy(X)).detach().numpy()\n",
    "diff = ym - y\n",
    "print(np.amax(diff, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source terms\n",
    "### Single reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X rAB min:  [  1.46467255e-04   1.90126350e-02   4.70975454e-01]\n",
      "X rAB max:  [ 0.02410139  0.99859163  0.99996662]\n",
      "y rAB min:  [ 0.01899498]\n",
      "y rAB max:  [ 0.96005602]\n"
     ]
    }
   ],
   "source": [
    "data = data_files[\"single\"]\n",
    "scaler_X_rAB = MinMaxScaler()\n",
    "scaler_y_rAB = MinMaxScaler()\n",
    "X01_rAB = scaler_X_rAB.fit_transform(data[[\"dist\", \"A_av\", \"B_av\"]].values)\n",
    "y01_rAB = scaler_y_rAB.fit_transform(data[[\"rAB_av\"]].values)\n",
    "print(\"X rAB min: \", scaler_X_rAB.data_min_)\n",
    "print(\"X rAB max: \", scaler_X_rAB.data_max_)\n",
    "print(\"y rAB min: \", scaler_y_rAB.data_min_)\n",
    "print(\"y rAB max: \", scaler_y_rAB.data_max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"n_inputs\"] = 3\n",
    "\n",
    "model_r = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"single_rAB_av.pt\"\n",
    "model_r.load_state_dict(torch.load(model_path))\n",
    "model_r.eval()\n",
    "\n",
    "full_R_model = R_Model(model_r,\n",
    "                       scaler_X_rAB.data_max_, scaler_X_rAB.data_min_,\n",
    "                       scaler_y_rAB.data_max_, scaler_y_rAB.data_min_)\n",
    "\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\"]].values\n",
    "model_trace = torch.jit.trace(full_R_model, torch.from_numpy(X[0]).unsqueeze(-1).T)\n",
    "model_trace.save(output_path_model + \"rAB_model_single.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00648585085187\n"
     ]
    }
   ],
   "source": [
    "# sanity test\n",
    "rAB_model_single = torch.jit.load(output_path_model + \"rAB_model_single.pt\")\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\"]].values\n",
    "y = data[[\"rAB_av\"]].values[:,0]\n",
    "ym = rAB_model_single(torch.from_numpy(X)).detach().numpy()\n",
    "diff = ym - y\n",
    "print(np.amax(diff, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consecutive reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X rAB min:  [  1.46467255e-04   1.90126183e-02   4.76073262e-01]\n",
      "X rAB max:  [ 0.02410139  0.99723356  0.99996662]\n",
      "y rAB min:  [ 0.01899496]\n",
      "y rAB max:  [ 0.96003565]\n"
     ]
    }
   ],
   "source": [
    "data = data_files[\"cons\"]\n",
    "scaler_X_rAB = MinMaxScaler()\n",
    "scaler_y_rAB = MinMaxScaler()\n",
    "X01_rAB = scaler_X_rAB.fit_transform(data[[\"dist\", \"A_av\", \"B_av\"]].values)\n",
    "y01_rAB = scaler_y_rAB.fit_transform(data[[\"rAB_av\"]].values)\n",
    "print(\"X rAB min: \", scaler_X_rAB.data_min_)\n",
    "print(\"X rAB max: \", scaler_X_rAB.data_max_)\n",
    "print(\"y rAB min: \", scaler_y_rAB.data_min_)\n",
    "print(\"y rAB max: \", scaler_y_rAB.data_max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"n_inputs\"] = 3\n",
    "\n",
    "model_r = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"cons_rAB_av.pt\"\n",
    "model_r.load_state_dict(torch.load(model_path))\n",
    "model_r.eval()\n",
    "\n",
    "full_R_model = R_Model(model_r,\n",
    "                       scaler_X_rAB.data_max_, scaler_X_rAB.data_min_,\n",
    "                       scaler_y_rAB.data_max_, scaler_y_rAB.data_min_)\n",
    "\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\"]].values\n",
    "model_trace = torch.jit.trace(full_R_model, torch.from_numpy(X[0]).unsqueeze(-1).T)\n",
    "model_trace.save(output_path_model + \"rAB_model_cons.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00536666522764\n"
     ]
    }
   ],
   "source": [
    "# sanity test\n",
    "rAB_model_cons = torch.jit.load(output_path_model + \"rAB_model_cons.pt\")\n",
    "X = data[[\"dist\", \"A_av\", \"B_av\"]].values\n",
    "y = data[[\"rAB_av\"]].values[:,0]\n",
    "ym = rAB_model_cons(torch.from_numpy(X)).detach().numpy()\n",
    "diff = ym - y\n",
    "print(np.amax(diff, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X rAP min:  [  1.46467255e-04   1.90126183e-02   3.33430253e-05]\n",
      "X rAP max:  [ 0.02410139  0.99723356  0.24925557]\n",
      "y rAP min:  [  1.76337889e-05]\n",
      "y rAP max:  [ 0.24854635]\n"
     ]
    }
   ],
   "source": [
    "data = data_files[\"cons\"]\n",
    "scaler_X_rAP = MinMaxScaler()\n",
    "scaler_y_rAP = MinMaxScaler()\n",
    "X01_rAP = scaler_X_rAP.fit_transform(data[[\"dist\", \"A_av\", \"P_av\"]].values)\n",
    "y01_rAP = scaler_y_rAP.fit_transform(data[[\"rAP_av\"]].values)\n",
    "print(\"X rAP min: \", scaler_X_rAP.data_min_)\n",
    "print(\"X rAP max: \", scaler_X_rAP.data_max_)\n",
    "print(\"y rAP min: \", scaler_y_rAP.data_min_)\n",
    "print(\"y rAP max: \", scaler_y_rAP.data_max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"n_inputs\"] = 3\n",
    "\n",
    "model_r = hm.SimpleMLP(**model_dict)\n",
    "model_path = output_path_model + \"cons_rAP_av.pt\"\n",
    "model_r.load_state_dict(torch.load(model_path))\n",
    "model_r.eval()\n",
    "\n",
    "full_R_model = R_Model(model_r,\n",
    "                       scaler_X_rAP.data_max_, scaler_X_rAP.data_min_,\n",
    "                       scaler_y_rAP.data_max_, scaler_y_rAP.data_min_)\n",
    "\n",
    "X = data[[\"dist\", \"A_av\", \"P_av\"]].values\n",
    "model_trace = torch.jit.trace(full_R_model, torch.from_numpy(X[0]).unsqueeze(-1).T)\n",
    "model_trace.save(output_path_model + \"rAP_model_cons.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00176690606511\n"
     ]
    }
   ],
   "source": [
    "# sanity test\n",
    "rAP_model_cons = torch.jit.load(output_path_model + \"rAP_model_cons.pt\")\n",
    "X = data[[\"dist\", \"A_av\", \"P_av\"]].values\n",
    "y = data[[\"rAP_av\"]].values[:,0]\n",
    "ym = rAP_model_cons(torch.from_numpy(X)).detach().numpy()\n",
    "diff = ym - y\n",
    "print(np.amax(diff, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
