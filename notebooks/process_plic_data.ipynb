{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read, clean, merge, and write PLIC facets\n",
    "\n",
    "The Basilisk simulations write PLIC facecets to the folder *plic/* of each simulation. The PLIC points are written after **10** iterations. Each process stores the points in a separate file. The files are named as\n",
    "\n",
    "points_**iteration**_n**process**.txt\n",
    "\n",
    "For example, the file of process 8 after 120 iterations is called\n",
    "\n",
    "points_**000120**_n**008**.txt\n",
    "\n",
    "Each file contains the all points in Cartesian coordinates. The points belonging to one PLIC facet are separated by one empty line. In the following example, the first facet consists of **three** and the second of **four** vertices:\n",
    "```\n",
    "# the order is px / py / pz\n",
    "-0.472504 3.39844 -0.0585938 # first point of facet one\n",
    "-0.46875 3.38866 -0.0585938\n",
    "-0.46875 3.39844 -0.0823362\n",
    "\n",
    "-0.474992 3.39844 -0.0292969 # first point of facet two\n",
    "-0.46875 3.38206 -0.0292969\n",
    "-0.46875 3.38931 -0.0585938\n",
    "-0.47223 3.39844 -0.0585938\n",
    "...\n",
    "```\n",
    "In two-dimensional data sets the entry **pz** is missing. For 2D cases, pass *shape_2D=True* as argument to the *process_shape* function\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "This notebook depends on no other notebooks. It accesses the raw, distribited Basilisk output files provided in the data set accompanying this repository, and writes merged PLIC files in the *plic_clean* folder of each Basilisk simulation.\n",
    "\n",
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 water_01_l14\n",
      "1 water_01_l15\n",
      "2 water_01_l16\n",
      "3 water_03_l14\n",
      "4 water_03_l15\n",
      "5 water_03_l16\n",
      "6 water_05_l14\n",
      "7 water_05_l15\n",
      "8 water_05_l16\n",
      "9 bhaga_02_l14\n",
      "10 bhaga_02_l15\n",
      "11 bhaga_02_l16\n",
      "12 bhaga_03_l14\n",
      "13 bhaga_03_l15\n",
      "14 bhaga_03_l16\n",
      "15 bhaga_04_l14\n",
      "16 bhaga_04_l15\n",
      "17 bhaga_04_l16\n"
     ]
    }
   ],
   "source": [
    "# paths to define from where to read and where to write the processed data\n",
    "source_base = \"../data\"\n",
    "target_base = \"../data\"\n",
    "# the processed data will be stored in the newly created folder plic_clean\n",
    "plic_source = \"plic\"\n",
    "plic_target = \"plic_clean\"\n",
    "\n",
    "bhaga_cases = [\"bhaga_{:02d}\".format(case) + \"_l\" + str(level) for case in [2, 3, 4] for level in [14, 15, 16]]\n",
    "water_cases = [\"water_{:02d}\".format(case) + \"_l\" + str(level) for case in [1, 3, 5] for level in [14, 15, 16]]\n",
    "cases = water_cases + bhaga_cases\n",
    "\n",
    "for i, case in enumerate(cases):\n",
    "    print(i, case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def countNan(px):\n",
    "    '''Count the time the passed argument is a NAN\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    px - float : either a float or NAN\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    count - int : number of times a NAN was passed as argument\n",
    "    '''\n",
    "    if pd.isna(px):\n",
    "        countNan.counter += 1   \n",
    "    return countNan.counter\n",
    "    \n",
    "\n",
    "def process_shape(path, iteration, shape_2D=False):\n",
    "    '''Read PLIC intersections points from disk.\n",
    "       The function reads all avaialable processor files und concatenates them.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    path - string: path to the file location\n",
    "    iteration - integer: iteration to load\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    facets - DataFrame: DataFrame containing the x, y, z coordintes and\n",
    "             the number of the facet to which a pints belongs\n",
    "             \n",
    "    '''\n",
    "    base_name = path + \"/points_{:06d}_n\".format(iteration)\n",
    "    files = sorted(glob.glob(base_name + \"*\"))\n",
    "    points = []\n",
    "    if shape_2D:\n",
    "        columns = [\"px\", \"py\"]\n",
    "    else:\n",
    "        columns = [\"px\", \"py\", \"pz\"]\n",
    "    for file in files:\n",
    "        points.append(pd.read_csv(file, sep=\" \", names=columns, engine='c', dtype=np.float32))\n",
    "    all_points = pd.concat(points)\n",
    "    countNan.counter = 0\n",
    "    all_points[\"element\"] = all_points[\"px\"].apply(countNan)\n",
    "    all_points.dropna(inplace=True)\n",
    "    return all_points.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def get_iterations(path):\n",
    "    ''' Find all iterations based on the file names.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path - string : where to search for files\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    iterations - array-like : set of all iterations\n",
    "    \n",
    "    '''\n",
    "    file_paths = glob.glob(path + \"/*_n000.txt\")\n",
    "    iterations = sorted([int(path.split(\"/\")[-1].split(\"_\")[1]) for path in file_paths])\n",
    "    return iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.54it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.47it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 98.88it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing simulation folder water_01_l14\n",
      "Processing simulation folder water_01_l15\n",
      "Processing simulation folder water_01_l16\n",
      "Processing simulation folder water_03_l14\n",
      "Processing simulation folder water_03_l15\n",
      "Processing simulation folder water_03_l16\n",
      "Processing simulation folder water_05_l14\n",
      "Processing simulation folder water_05_l15\n",
      "Processing simulation folder water_05_l16\n",
      "Processing simulation folder bhaga_02_l14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 95.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.65it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing simulation folder bhaga_02_l15\n",
      "Processing simulation folder bhaga_02_l16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 90.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.79it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 91.12it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.21it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing simulation folder bhaga_03_l14\n",
      "Processing simulation folder bhaga_03_l15\n",
      "Processing simulation folder bhaga_03_l16\n",
      "Processing simulation folder bhaga_04_l14\n",
      "Processing simulation folder bhaga_04_l15\n",
      "Processing simulation folder bhaga_04_l16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 68.54it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "for case in cases:\n",
    "    print(\"Processing simulation folder {}\".format(case))\n",
    "    source = source_base + \"/\" + case + \"/\" + plic_source\n",
    "    iterations = get_iterations(source)\n",
    "    target = target_base + \"/\" + case + \"/\" + plic_target\n",
    "    if not os.path.exists(target):\n",
    "        os.makedirs(target)\n",
    "    for it in tqdm(iterations):\n",
    "        data = process_shape(source, it, shape_2D=True)\n",
    "        file_name = \"plic_{:06d}.pkl\".format(it)\n",
    "        data.to_pickle(target + \"/\" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
